{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7649d0-c501-49ea-b26f-19ec46b86b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from datasets import Dataset\n",
    "\n",
    "original_sample_rate = 48000\n",
    "target_sample_rate = 16000\n",
    "\n",
    "programming_data = {\n",
    "    'text': [\n",
    "        'AWS', 'Docker', 'Kubernetes', 'Machine Learning', 'Artificial Intelligence', \n",
    "        'DevOps', 'Microservices', 'REST API', 'GraphQL', 'Continuous Integration', \n",
    "        'Continuous Deployment', 'Blockchain', 'Big Data', 'Data Science', \n",
    "        'Serverless', 'Agile', 'Scrum', 'Virtualization', 'Cloud Computing', \n",
    "        'Cybersecurity', 'Internet of Things', 'Front-end', 'Back-end', \n",
    "        'Full-stack', 'API Gateway', 'NoSQL', 'SQL', 'Data Warehouse', \n",
    "        'Data Lake', 'ETL', 'Containers', 'Orchestration', \n",
    "        'CI/CD', 'Version Control', 'Git', 'Python', 'Java', \n",
    "        'JavaScript', 'TypeScript', 'Ruby on Rails', 'Flask', 'Django', \n",
    "        'React', 'Angular', 'Vue.js', 'Bootstrap', 'jQuery', \n",
    "        'Sass', 'HTML5', 'CSS3'\n",
    "    ],\n",
    "    'audio_paths': [\n",
    "        'D:/datasets/audio1.wav', 'D:/datasets/audio2.wav', 'D:/datasets/audio3.wav',\n",
    "        'D:/datasets/audio4.wav', 'D:/datasets/audio5.wav', 'D:/datasets/audio6.wav',\n",
    "        'D:/datasets/audio7.wav', 'D:/datasets/audio8.wav', 'D:/datasets/audio9.wav',\n",
    "        'D:/datasets/audio10.wav', 'D:/datasets/audio11.wav', 'D:/datasets/audio12.wav',\n",
    "        'D:/datasets/audio13.wav', 'D:/datasets/audio14.wav', 'D:/datasets/audio15.wav',\n",
    "        'D:/datasets/audio16.wav', 'D:/datasets/audio17.wav', 'D:/datasets/audio18.wav',\n",
    "        'D:/datasets/audio19.wav', 'D:/datasets/audio20.wav', 'D:/datasets/audio21.wav',\n",
    "        'D:/datasets/audio22.wav', 'D:/datasets/audio23.wav', 'D:/datasets/audio24.wav',\n",
    "        'D:/datasets/audio25.wav', 'D:/datasets/audio26.wav', 'D:/datasets/audio27.wav',\n",
    "        'D:/datasets/audio28.wav', 'D:/datasets/audio29.wav', 'D:/datasets/audio30.wav',\n",
    "        'D:/datasets/audio31.wav', 'D:/datasets/audio32.wav', 'D:/datasets/audio33.wav',\n",
    "        'D:/datasets/audio34.wav', 'D:/datasets/audio35.wav', 'D:/datasets/audio36.wav',\n",
    "        'D:/datasets/audio37.wav', 'D:/datasets/audio38.wav', 'D:/datasets/audio39.wav',\n",
    "        'D:/datasets/audio40.wav', 'D:/datasets/audio41.wav', 'D:/datasets/audio42.wav',\n",
    "        'D:/datasets/audio43.wav', 'D:/datasets/audio44.wav', 'D:/datasets/audio45.wav',\n",
    "        'D:/datasets/audio46.wav', 'D:/datasets/audio47.wav', 'D:/datasets/audio48.wav',\n",
    "        'D:/datasets/audio49.wav', 'D:/datasets/audio50.wav'\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdead196-b25b-4583-9709-09885d39630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'audio'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_data = []\n",
    "\n",
    "for audio_path in acronyms_data['audio_paths']:\n",
    "    audio, sr = librosa.load(audio_path, sr=original_sample_rate)\n",
    "    \n",
    "    # Resample the audio\n",
    "    if sr != target_sample_rate:\n",
    "        resampled_audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sample_rate)\n",
    "    else:\n",
    "        resampled_audio = audio\n",
    "    \n",
    "    audio_data.append(resampled_audio)\n",
    "\n",
    "\n",
    "acronym_dataset = Dataset.from_dict({\n",
    "    'text': acronyms_data['text'],\n",
    "    'audio': audio_data\n",
    "})\n",
    "\n",
    "\n",
    "print(acronym_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e07e8c-4dab-4fd7-bc80-c8b9af183d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa22fac9674f4cf9b60088f6791ca34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sowjanya Narisetty\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import  AutoTokenizer, Trainer, TrainingArguments\n",
    "# Preprocess the dataset\n",
    "def preprocess_function(batch):\n",
    "    return {\n",
    "        'input_values': [np.array(audio).tolist() for audio in batch['audio']],  # Convert to list if needed\n",
    "        'labels': batch['text']\n",
    "    }\n",
    "\n",
    "# Preprocess the dataset\n",
    "processed_dataset = acronym_dataset.map(preprocess_function)\n",
    "\n",
    "model_name = \"microsoft/speecht5_tts\"  \n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(model_name)\n",
    "processor = SpeechT5Processor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c2976-647b-4096-8b20-0c50f7202ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
